{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T02:43:24.467253Z",
     "start_time": "2019-02-09T02:43:24.307478Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"deep-learning-from-scratch\")\n",
    "from dataset.mnist import load_mnist\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=True, normalize=False)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(t_train.shape)\n",
    "print(x_test.shape)\n",
    "print(t_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T03:08:25.224340Z",
     "start_time": "2019-02-09T03:08:24.882445Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ Sigmoid $\n",
    "\n",
    "\\begin{equation}\n",
    "  h(x) = \\frac\n",
    "  {1}\n",
    "  {1 + \\exp(-x)}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ ReLU $\n",
    "\n",
    "\\begin{equation}\n",
    "  h(x) = \\begin{cases}\n",
    "  x & (x > 0) \\\\\n",
    "  0 & (x \\le 0)\n",
    "  \\end{cases}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ Softmax $\n",
    "\n",
    "\\begin{equation}\n",
    "  y_k = \\frac\n",
    "  { \\exp(a_k) }\n",
    "  { \\displaystyle \\sum_{i=1}^{n} \\exp(a_i) }\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T11:08:45.108429Z",
     "start_time": "2019-02-07T11:08:45.099344Z"
    }
   },
   "outputs": [],
   "source": [
    "def step_function(x):\n",
    "    return np.array(x > 0, dtype=np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T11:11:52.002254Z",
     "start_time": "2019-02-07T11:11:51.995731Z"
    }
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T11:18:25.772118Z",
     "start_time": "2019-02-07T11:18:25.763435Z"
    }
   },
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(0, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T11:30:13.220616Z",
     "start_time": "2019-02-07T11:30:13.054124Z"
    }
   },
   "outputs": [],
   "source": [
    "x = np.arange(-5.0, 5.0, 0.1)\n",
    "y1 = step_function(x)\n",
    "y2 = sigmoid(x)\n",
    "y3 = relu(x)\n",
    "plt.plot(x, y1, label=\"step\")\n",
    "plt.plot(x, y2, label=\"Sigmoid\")\n",
    "plt.plot(x, y3, label=\"ReLU\")\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T13:12:46.392977Z",
     "start_time": "2019-02-07T13:12:46.383002Z"
    }
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    a = np.exp(x - np.max(x))\n",
    "    return a / np.sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T03:21:07.204823Z",
     "start_time": "2019-02-09T03:21:06.950036Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import *\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=True, normalize=False)\n",
    "\n",
    "img = x_train[0]\n",
    "label = t_train[0]\n",
    "print(label)\n",
    "print(img.shape)\n",
    "img = img.reshape(28, 28)\n",
    "print(img.shape)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T05:59:58.895954Z",
     "start_time": "2019-02-09T05:59:58.877583Z"
    }
   },
   "outputs": [],
   "source": [
    "y = np.array([[1, 5], [8, 4], [3, 7]])\n",
    "display(y)\n",
    "np.argmax(y, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ ２乗和誤差 $\n",
    "\\begin{equation}\n",
    "  E = \\frac{1}{2}\\sum_k (y_k - t_k)^2\n",
    "\\end{equation}\n",
    "\n",
    "* t: 正解\n",
    "* y: 出力"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ 交差エントロピー誤差 $\n",
    "\\begin{equation}\n",
    "  E = -\\sum_k t_k \\log y_k\n",
    "\\end{equation}\n",
    "\n",
    "* t: 正解\n",
    "* y: 出力\n",
    "\n",
    "但し値は 0　か 1 のみを取り、１が正解とする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_error(y, t):\n",
    "    return -np.sum(t * np.log(y + 1e -7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-11T02:34:04.568529Z",
     "start_time": "2019-02-11T02:34:04.559538Z"
    }
   },
   "outputs": [],
   "source": [
    "class TwoLayerNet:\n",
    "    def __init__(self, input_size, hidden_size, output_size, wegith_init_std=0.01):\n",
    "        self.params = {}\n",
    "        self.params['W1'] = wegith_init_std * np.random.randn(input_size, hidden_size)\n",
    "        self.params['b1'] = np.zeros(hidden_size)\n",
    "        self.params['W2'] = wegith_init_std * np.random.randn(hidden_size, output_size)\n",
    "        self.params['b2'] = np.zeros(output_size)\n",
    "        return\n",
    "        \n",
    "    def predict(self, x):\n",
    "        W1, W2 = self.params['W1'], self.params['W2']\n",
    "        b1, b2 = self.params['b1'], self.params['b2']\n",
    "        \n",
    "        a1 = np.dot(x, W1) + b1\n",
    "        z1 = sigmoid(a1)\n",
    "        a2 = np.dot(z1, W2) + b2\n",
    "        return softmax(a2)\n",
    "    \n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        return cross_entropy_error(y, t)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
